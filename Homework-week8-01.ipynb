{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础概念复习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 机器学习方法主要用在什么特点的场景下？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use machine learning for the following situations:\n",
    "\n",
    "You cannot code the rules: Many human tasks (such as recognizing whether an email is spam or not spam) cannot be adequately solved using a simple (deterministic), rule-based solution. A large number of factors could influence the answer. When rules depend on too many factors and many of these rules overlap or need to be tuned very finely, it soon becomes difficult for a human to accurately code the rules. You can use ML to effectively solve this problem.\n",
    "\n",
    "You cannot scale: You might be able to manually recognize a few hundred emails and decide whether they are spam or not. However, this task becomes tedious for millions of emails. ML solutions are effective at handling large-scale problems.\n",
    "\n",
    "机器学习的关键要素：\n",
    "1. 存在一个模式或者说表现可以让我们对它进行改进提高；\n",
    "2. 规则并不容易那么定义；\n",
    "3. 需要有数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 提出 3 个你认为使用了机器学习方法的现实场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最典型的是：\n",
    "1. 淘宝中给我们的推荐，网易云音乐给的推荐等；\n",
    "2. 机器翻译，自动摘要生成；\n",
    "3. 高铁安检的人脸识别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 提出 3 个你认为可以使用机器学习但是还没有使用机器学习方法的场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 在农业上对于作物的监控后分析，提升作物产量质量； \n",
    "2. 教育上，比如完全可以根据大学生的成绩情况进行提醒避免出现更差的后果；\n",
    "3. 利用饭店分布，预测在什么地方开店，开什么店赚钱。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 什么是“模型”？ 为什么说“All models are wrong, but some useful”。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型是对现实世界的拟合和抽象。因为是抽象，所以肯定会失去一些精确性不是完全地刻画，但是也是拟合，所以对于我们关键的部分是有效的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classification 和 Regression 主要针对什么？ 有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification 针对的是分类，Regression 针对的是预测。定量输出称为回归，或者说是连续变量预测；定性输出称为分类，或者说是离散变量预测。\n",
    "\n",
    "Andrew Ng:\n",
    "“Supervised learning problems are categorized into \"regression\" and \"classification\" problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in adiscrete output. In other words, we are trying to map input variables into discrete categories.”\n",
    "\n",
    "但是，连续的变量也可以离散化（课上老师讲的例子），回归有“度量”的意思在其中，而分类则没有。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Precision， Recall，$F1$，Auc 分别是什么意思？ 假设一个城市有 10000 人，有 30 个犯罪分子，警察抓到了 35 个人，其中 20 个是犯罪分子，请问这个警察的 Precision， Recall，$F1$,  Auc  分别是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记号：\n",
    "\n",
    "1. True negative(TN)，称为真阴率，表明实际是负样本预测成负样本的样本数，本例中 TN = 865\n",
    "2. False positive(FP)，称为假阳率，表明实际是负样本预测成正样本的样本数，本例中 FP = 15\n",
    "3. False negative(FN)，称为假阴率，表明实际是正样本预测成负样本的样本数，本例中 FN = 10\n",
    "4. True positive(TP)，称为真阳率，表明实际是正样本预测成正样本的样本数，本例中 TP = 20\n",
    "\n",
    "\n",
    "精确率（precision）是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)，也就是\n",
    "\n",
    "$$\n",
    "P=\\frac{T P}{T P+F P}.\n",
    "$$\n",
    "\n",
    "在本例中 $$P=\\frac{20}{35}.$$\n",
    "\n",
    "召回率（recall）是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)。\n",
    "\n",
    "$$\n",
    "R=\\frac{T P}{T P+F N}.\n",
    "$$\n",
    "\n",
    "在本例中 $R=\\frac{20}{30}.$\n",
    "\n",
    "注意：准确率和召回率的计算公式中其实就是分母不同，一个分母是预测为正的样本数，另一个是原来样本中所有的正样本数。一般来说呢，鱼与熊掌不可兼得。如果你的模型很贪婪，想要覆盖更多的正类，那么它就更有可能犯错。在这种情况下，你会有很高的召回率，但是较低的精确率。如果你的模型很保守，只对它很确定的样本作出预测，那么你的精确率会很高，但是召回率会相对低。 $F1$ 就是一个综合考虑精度和召回率的度量：\n",
    "\n",
    "$$F1 = \\frac{2 P R}{P+ R}.$$\n",
    "\n",
    "在本例中 $F1 = \\frac{2\\frac{20}{35}\\cdot\\frac{20}{30}}{\\frac{20}{35}+\\frac{20}{30}}.$\n",
    "\n",
    "ROC 曲线：假阳率，简单通俗来理解就是预测为正样本但是预测错了的可能性，显然，我们不希望该指标太高。\n",
    "$$\n",
    "F P R=\\frac{F P}{T N+F P}.\n",
    "$$\n",
    "在本例中 $FRP=\\frac{15}{880}.$\n",
    "\n",
    "真阳率（和召回率一样），则是代表预测为正样本但是预测对了的可能性，当然，我们希望真阳率越高越好。\n",
    "\n",
    "$$\n",
    "T P R=\\frac{T P}{T P+F N}.\n",
    "$$\n",
    "\n",
    "一条 ROC 曲线，它的横轴是 FPR，纵轴是 TPR。AUC 是 ROC 曲线与横坐标的面积。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 请提出两种场景，第一种场景下，对模型的评估很注重 precision, 第二种很注重 recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如有一场考试，我的能力水平有限，有的题我会有的题我不会，并且题量特别大，我必须选择一部分题目作答。这时候我就比较注重 precision。我要确保我选的题目尽量答对，这样我能取得相对较高的分数。注重 precision 的思想是：放掉那些不确定的。\n",
    "\n",
    "比如我是一个卖车的，我生产了一批车，结果发现有的车有质量问题，因为这个责任重大，所以我要告诉一些车主我的车有问题。这时候我就比较注重 recall，我宁可告诉尽量多的车主车是有问题的以确保尽可能多的有问题的车能够返厂。注重 recall 的思想是：宁可错杀一千不能放过一个。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 什么是 Overfitting， 什么是 Underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠拟合是模型不能再训练集上获得足够低的误差，而过拟合则是训练误差和测试误差之间的差距太大。一个影响因素是容量（capacity），也就是模型空间拟合各种函数的能力。如果容量低，则可能出现模型难以拟合训练集的情况，导致欠拟合（高偏差）；如果容量高，则因为模型记住了不适用于测试集的训练集性质，导致过拟合（高方差）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  9. Lazy-Learning， Lazy 在哪里？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此类学习技术在训练阶段仅仅是将样本存储起来，训练开销为零，待收到测试样本后再进行处理；它是基于记忆的非参数估计方法。将样本保存于内存中，当有查询需求的时候，取出一组样本用于计算状态的估计值。典型的例子就是 KNN。在任务数据更替频繁时候，可采用 (lazy learning) 方式，先不进行任何训练，待收到预测请求时再根据当前数据集进行概率估值。 Lasy 的意思是它不进行“训练”，而重点在于记忆。\n",
    "\n",
    "相应的，那些在训练阶段就对样本进行学习处理的方法，称为“急切学习”（eager learning）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Median， Mode， Mean 分别是什么？ 有什么意义？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.平均数首先平均数是一组【常规】样本【大概率上】最有代表性的统计量。有时候平均数并不能反映出样本的真实特征来。以平均工资举例，经常有很多人吐槽自己的工资被“平均”了，其实这就是偏态分布导致平均数无法描述整体样本的情况，那么在平均数有点失灵时，我们就需要其他统计量登场了。\n",
    "\n",
    "2.中位数是一个很常见的，用来弥补平均数在偏态分布中不足之处的，有很好用的统计量。根据平均数的计算方法我们知道，样本中任何一个数值的改变都会影响最终计算结果，那如有一个数值出现了极大的离群变化，则平均值就可能失效。反观中位数的，前后均是98，相对而言能更好的反映样本情况。因此中位数通常会在样本出现少数离群值的时候，用于提供相对尊重样本主要情况统计量。其算法也反映了该特点——某一个数值的变动，尤其是边界上的变动，不一定会改变该统计量的数值——所以在偏态分布时，用中位数更加具有实际意义。例子：国家统计局发布数据，2015年城镇居民家庭人均可支配收入31790.30元，而人均可支配收入的中位数是29129.00元，说明收入就是一定程度的部分评分制竞技体育赛事的分数计算方法为：去掉一个最高分，去掉一个最低分，平均分是XXX，这其实就是兼顾了平均数和中位数特质的又一个统计量。\n",
    "\n",
    "3.众数与前两者区别较大。平均数和中位数都是用来尽可能反映样本整体情况：一组样本从整体上来讲，围绕在哪个数值周围；而众数则反映的是局部特征——一组样本在哪里最密集。这个统计量一般要根据具体的需要和样本特征来使用。\n",
    "\n",
    "每一个统计量都不能反映全部特征，但每一个却也都能反映出一定程度的信息。因此不同统计量的意义就是在不同维度反映样本性质。\n",
    "\n",
    "参考资料：https://www.zhihu.com/question/286260644/answer/451485855"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Outlier（异常值、离群值）是什么？ 如何定义？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "离群点指的是，一个观测值与其他观测值偏离太多，而引起猜疑，觉得它由一个不同的机制产生。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Bias 和 Variance 有什么关系？ 他们之间为什么是一种 tradeoff 的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BV](https://pic2.zhimg.com/80/v2-286539c808d9a429e69fd59fe33a16dd_hd.png)\n",
    "\n",
    "参考资料：https://www.zhihu.com/question/27068705/answer/137487142\n",
    "\n",
    "Bias 描述的是根据样本拟合出的模型的输出预测结果的期望与样本真实结果的差距，简单讲，就是在样本上拟合的好不好。要想在bias上表现好，low bias，就得复杂化模型，增加模型的参数，但这样容易过拟合 (overfitting)，过拟合对应上图是 high variance，点很分散。low bias对应就是点都打在靶心附近，所以瞄的是准的，但手不一定稳。Varience 描述的是样本上训练出来的模型在测试集上的表现，要想在 variance 上表现好，low varience，就要简化模型，减少模型的参数，但这样容易欠拟合(unfitting)，欠拟合对应上图是 high bias，点偏离中心。low variance 对应就是点都打的很集中，但不一定是靶心附近，手很稳，但是瞄的不准。这个靶子上的点(hits)可以理解成一个一个的拟合模型，如果许多个拟合模型都聚集在一堆，位置比较偏，如图中 high bias low variance 这种情景，意味着无论什么样子的数据灌进来，拟合的模型都差不多，这个模型过于简陋了，参数太少了，复杂度太低了，这就是欠拟合；但如果是图中 low bias high variance 这种情景，你看，所有拟合模型都围绕中间那个 correct target 均匀分布，但又不够集中，很散，这就意味着，灌进来的数据一有风吹草动，拟合模型就跟着剧烈变化，这说明这个拟合模型过于复杂了，不具有普适性，就是过拟合。所以 bias 和 variance 的选择是一个 tradeoff，过高的 variance 对应的概念\n",
    "\n",
    "我们训练一个模型的最终目的，是为了让这个模型在测试数据上拟合效果好，也就是 Error(test) 比较小，但在实际问题中，test data我们是拿不到的，也根本不知道 test data 的内在规律（如果知道了，还 machine learning 个啥 ），所以我们通过什么策略来减小 Error(test) 呢？分两步：让 Error(train) 尽可能小让 Error(train) 尽可能等于 Error(test)。\n",
    "\n",
    "三段论，因为 A 小，而且 A=B，这样 B 就小。那么怎么让 Error(train) 尽可能小呢？把模型复杂化，把参数搞得多多的，这个好理解，十元线性回归，肯定 error 要比二元线性回归低啊。low bias 然后怎么让 Error(train) 尽可能等于 Error(test) 呢？把模型简单化，把参数搞得少少的。什么叫 Error(train)=Error(test)？就是模型没有偏见，对 train test 一视同仁。那么怎样的模型更容易有这这种一视同仁的特性，换句话说，更有『通用性』，对局部数据不敏感？那就是简单的模型。low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Train， Validation，Test 数据集之间是什么关系？ 为什么要这么划分？"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 用来训练模型内参数的数据集\n",
    "2. 用于在训练过程中检验模型的状态，收敛情况。验证集通常用于调整超参数，根据几组模型验证集上的表现决定哪组超参数拥有最好的性能。 同时验证集在训练过程中还可以用来监控模型是否发生过拟合，一般来说验证集表现稳定后，若继续训练，训练集表现还会继续上升，但是验证集会出现不升反降的情况，这样一般就发生了过拟合。所以验证集也用来判断何时停止训练\n",
    "3. 测试集用来评价模型泛化能力，即之前模型使用验证集确定了超参数，使用训练集调整了参数，最后使用一个从没有见过的数据集来判断这个模型是否有效。\n",
    "\n",
    "形象上来说训练集就像是学生的课本，学生 根据课本里的内容来掌握知识，验证集就像是作业，通过作业可以知道 不同学生学习情况、进步的速度快慢，而最终的测试集就像是考试，考的题是平常都没有见过，考察学生举一反三的能力。\n",
    "\n",
    "参考资料：https://www.ph0en1x.space/2018/04/01/cross_validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Supervised Learning 的 Supervised 体现在什么地方？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常是包含有标签样本（training examples）的数据集（data set），也就是说有“老师”（标签）告诉你你做的对不对。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Linear Regression 中，什么是“线性关系”？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于变量（特征的）一次多元多项式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Linear Regression 中，Loss 函数怎么定义的？ 为什么要写成这样？ 什么是凸函数？ 优化中有什么意义？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. 简述 Gradient Descent 的过程，以 $y = -10 x^2 + 3x + 4 $ 为例，从一个任一点 $ x = 10 $ 开始，如果根据 Gradient Descent 找到最值。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于函数 $f(x)$ 来说，梯度是下降速度最快的方向：\n",
    "\n",
    "$$\n",
    "\\nabla f(\\mathbf{x})=\\left(\\frac{\\partial f}{\\partial x_{1}}(\\mathbf{x}), \\cdots, \\frac{\\partial f}{\\partial x_{n}}(\\mathbf{x})\\right)\n",
    "$$\n",
    "\n",
    "梯度下降，简而言之就是：\n",
    "\n",
    "$$\n",
    "g(\\mathbf{x})={\\mathbf{x_0}-\\eta \\nabla f(\\mathbf{x})}.\n",
    "$$\n",
    "\n",
    "其中 $\\eta$ 是步长（学习率），如果 $\\eta>0$ 就是梯度下降，反之就是梯度上升。一旦达到收敛条件的话，迭代就结束。\n",
    "\n",
    "在这个例子里面，梯度就是导数了 $y'= 3 - 20 x$，直接 $y'=0$ 我们看到 $x=\\frac{3}{20}$。从而最大值是 $y_{max}=4.225$。\n",
    "利用梯度下降法，假设从 $x_0=10$ 开始，在 Mathematica 中：\n",
    "\n",
    "$$\\text{For}[i=0,i<20,i\\text{++},\\{x=x+0.02 (3-20 x),\\text{Print}[f(x)]\\}]$$\n",
    "\n",
    "用了 18 次就找到了最大值 $y_{max}=4.225$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. 一般在机器学习数量时，会做一个预处理（Normalization）， 简述 Normalization 的过程，以及数据经过 Normalization之后的平均值和标准差的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设有 $n$ 个样本 $x^1,x^2,\\cdots x^n$, 对于每个样本 $x^i=(x^1_1,x^1_2,\\ldots,x^n_m)$ 有 $m$ 个特征，对于 $1\\leq j \\leq m$：\n",
    "\n",
    "$$y^i = \\frac{x^i_j-\\overline{x}^i_j}{\\sigma^i_j},$$\n",
    "\n",
    "其中 $\\overline{x}^i_j$ 为 $x^1_j,x^2_j,\\ldots,x^n_j$ 的平均值，$\\sigma^i_j$ 为 $x^1_j,x^2_j,\\ldots,x^n_j$ 的标准差。由此得到的一组数据 $y^1,y^2,\\cdots y^n$ 称为样本 $x^1,x^2,\\cdots x^n$ 的标准化。经过处理的数据符合标准正态分布，即均值为 0，标准差为 1。\n",
    "\n",
    "这样做的好处是：如果特征的各个维度的取值范围不同，那么目标函数的等线很可能是一组椭圆，各个特征的取值范围差别越大，椭圆等高线会更加狭长。由于梯度方向垂直于等高线方向，因而这时优化路线会较为曲折，这样迭代会很慢，相比之下，如果特征的各个维度取值范围相近，那么目标函数很可能很接近一组于正圆，因而优化路线就会较为直接，迭代就会很快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Logistic Regression 的 Logstic 是什么曲线，被用在什么地方？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid函数，也称为逻辑函数（Logistic function）：\n",
    "\n",
    "$$\n",
    "g(z)=\\frac{1}{1+e^{-z}}.\n",
    "$$\n",
    "\n",
    "逻辑回归（Logistic Regression）是一种用于解决二分类（0 or 1）问题的机器学习方法，用于估计某种事物的可能性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Logistic Regression 的 Loss 函数 Cross Entropy 是怎么样的形式？ 有什么意义？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于拟合函数\n",
    "\n",
    "$$\n",
    "h_{\\theta}(x)=\\frac{1}{1+e^{-\\theta^{T} x}},\n",
    "$$\n",
    "\n",
    "其 Loss 函数为：\n",
    "\n",
    "$$\n",
    "J(\\theta)=\\frac{1}{2m} \\cdot\\left(-y^{T} \\log (h)-(1-y)^{T} \\log (1-h)\\right).\n",
    "$$\n",
    "\n",
    "这是极大似然估计。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
