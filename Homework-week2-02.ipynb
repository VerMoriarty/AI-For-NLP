{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Review of The Main Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How to Github and why do we use Jupyter and Pycharm？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook（http://jupyter.org/） 是一种 Web 应用，能让用户将说明文本、数学方程、代码和可视化内容全部组合到一个易于共享的文档中。\n",
    "\n",
    "Pycharm 是 Python 的 IDE 适合构建大型项目。而且很多功能(调试、语法高亮、Project管理、代码跳转、智能提示、自动完成、单元测试、版本控制)这些已经都已经内置了,不用另外安装插件。最爽的是它的代码跳转非常实用，当你写一个大几千行的项目，里面的类，函数很多的时候，就需要它方便的跳转。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "没分清楚概率模型和语言模型的区别，概率模型是更大的概念吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Can you came up with some scenarios at which we could use the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What's the Language Model？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本质上应该是这样的假定：在我们的语言中，每一种表达（字，词，句子等）满足一种概率分布。从而，每一种表达（比如句子）就都有其可能出现的概率了，对于这种概率分布的建模就是语言的概率模型。我们希望的目标是：如果这是一种符合规范的表达，那么它理应获得更高的概率；反正，如果表达本身不通顺或者没有意义，则应该获得较低的概率。并且，我们希望，越是常用的表达越应该获得更高的概率。也就是说，用概率给常用度打分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考资料：   http://www.flickering.cn/nlp/2015/02/%E6%88%91%E4%BB%AC%E6%98%AF%E8%BF%99%E6%A0%B7%E7%90%86%E8%A7%A3%E8%AF%AD%E8%A8%80%E7%9A%84-2%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Can you came up with some scenarios at which we could use Language Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最经典的场景就是文字的纠错，比如，我们日常使用拼音的时候，会因为输入法的原因打错字。例如：我们打“今天下大雨”时不小心打成了“今天下大鱼。”这里就应该被提醒。\n",
    "\n",
    "课上老师给出了几个应用的案例：\n",
    "1. 语音识别：在这里，我们关注的是语言模型的部分，假定我们大量可选的的同音字，利用概率模型就选出来最合适的那一种。\n",
    "2. OCR：假定我们已经识别出来一句话的绝大部分词，有一些词不确定，有几种备选。那么可以用概率模型选出来可能性最大的一种。\n",
    "3. 文本理解\n",
    "\n",
    "参考资料：\n",
    "https://web.stanford.edu/class/cs124/lec/languagemodeling.pdf    \n",
    "    Machine Translation:\n",
    "• $P(\\text{high winds tonite}) > P(\\text{large winds tonite})$\n",
    "    \n",
    "    Spell Correction:\n",
    "• $P(\\text{about fifteen minutes from}) > P(\\text{about fifteen minuets from})$\n",
    "\n",
    "    Speech Recognition:\n",
    "• $P(\\text{I saw a van}) >> P(\\text{eyes awe of an})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What's the 1-gram language model？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用链式法则，可以把一个句子的概率按照如下的方式拆解。设句子\n",
    "$ W $ 由 $w_1,w_2,\\ldots,w_m$ 组成，则\n",
    "\n",
    "$$P(W)=P(w_1)P(w_2|w_1)P(w_3|w_1w_2)\\cdots P(w_k|w_1w_2\\cdots w_m).$$\n",
    "\n",
    "显然，这样的条件概率并不好计算，也受限制于语料库（有太多的可能性，在这种情况下，我们没办法得到足够的预料）。\n",
    "\n",
    "(Markov Assumption) 一种考虑就是，我们假定每个词的概率分布只依赖于历史中最后的 $n-1$ 个词。这样的语言模型称为 $n-gram$ 模型。也就是说，在 $n-gram$ 模型中,  \n",
    "\n",
    "$${ P(W)=\\prod _{i=1}^{m}P(w_{i}\\mid w_{1}\\ldots w_{i-1})\\approx \\prod _{i=1}^{m}P(w_{i}\\mid w_{i-(n-1)}\\ldots w_{i-1})}.$$\n",
    "\n",
    "例如，1-gram 模型（又称 unigram model）就是假定，一句话的概率仅仅依赖没个词汇在文本中出现的概率：\n",
    "\n",
    "$$P(W)=\\prod_{i=1}^kP(w_i).$$\n",
    "\n",
    "2-gram 模型（又称 bigram model）：\n",
    "\n",
    "$$P(W)=\\prod_{i=1}^kP(w_i|w_{i-1}).$$\n",
    "\n",
    "3-gram 模型（又称 trigram model）：\n",
    "\n",
    "$$P(W)=\\prod_{i=1}^kP(w_i|w_{i-1}w_{i-2}).$$\n",
    "\n",
    "参考资料：https://en.wikipedia.org/wiki/Language_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. What's the disadvantages and advantages of 1-gram language model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在处理错别字时候 1-gram 是效果很明显，但是由于 1-gram 不考虑词汇之间的联系，所以因为上下文的原因产生的问题 1-gram 语言模型无法处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. What's the 2-gram models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "见 7 的回答，这里给一个例子（由 wiki 中英文句子改编）。\n",
    "\n",
    "$$ P({\\text{我看到一条狗}})\\approx P({\\text{我}})P({\\text{看到}}| {\\text{我}})P({\\text{一条}}| {\\text{看到}})P({\\text{狗}}| {\\text{一条}}).$$\n",
    "\n",
    "从例子中，我们可以看到，如果一句话是“我看到”，它的概率一定会比“我看到一条狗”的概率大。\n",
    "\n",
    "在这里说一些 N-gram 的过拟合危险：\n",
    "N-gram 在测试语料库和训练语料库类似的情况下效果比较好。（比如我们如果是新闻的语料库，那么在测试语境与之类似的情况下效果就比较好。）现实情况，不是如此。而且很有可能测试的语料库的词汇在训练的语料库中没有出现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. What's the web crawler, and can you implement a simple crawler?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：https://www.zhihu.com/question/24098641\n",
    "\n",
    "简单来讲，爬虫就是一个探测机器，它的基本操作就是模拟人的行为去各个网站溜达，点点按钮，查查数据，或者把看到的信息背回来。就像一只虫子在一幢楼里不知疲倦地爬来爬去。\n",
    "\n",
    "简单爬虫实例参考作业：Homework-week2-Regular Expression and the Web Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. There may be some issues to make our crwaler programming difficult, what are these, and how do we solve them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一可能因为网页本身反爬虫的原因，还有可能因为\n",
    "老师提供了两个方法：\n",
    "1. Beautiful Soup：Beautiful Soup 提供一些简单的、python 式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。Beautiful Soup 自动将输入文档转换为 Unicode 编码，输出文档转换为 utf-8 编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，Beautiful Soup 就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了。Beautiful Soup 已成为和 lxml、html6lib 一样出色的 python 解释器，为用户灵活地提供不同的解析策略或强劲的速度。\n",
    "\n",
    "2. WebKit\n",
    "\n",
    "（没有尝试）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. What's the Regular Expression and how to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正则表达式是一种特殊的符号序列帮助我们匹配、寻找字符串或者字符串集合。（A regular expression is a special sequence of characters that helps you match or find other strings or sets of strings）\n",
    "\n",
    "关于正则表达式参考作业：Homework-week2-Regular Expression and the Web Crawler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
